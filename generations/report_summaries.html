<!DOCTYPE html>
<html>
<head>
	<title>Summaries of the doc</title>
    <style>
        .center {
            text-align: center;
        }
    </style>
</head>
<body>
	<h1 class="center">High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity</h1>
	
		<h2>Page 1</h2>
		<p>This paper presents a new method based on a diffusion model (DM) to reconstruct images from human brain activity obtained via functional magnetic resonance imaging (fMRI). The method, called Stable Diffusion, is a latent diffusion model (LDM) that reduces the computational cost of DMs while preserving their high generative performance. The authors also characterize the inner mechanisms of the LDM by studying the relationship between its components (e.g. latent vector of image Z, conditioning inputs C, and different elements of the denoising U-Net) and distinct brain functions. Results show that the proposed method can reconstruct high-resolution images with high fidelity without additional training or fine-tuning of complex deep-learning models. This paper provides a new framework for understanding DMs and a promising method for reconstructing images from human brain activity.</p>
	
		<h2>Page 2</h2>
		<p>This page discusses the use of diffusion models and latent diffusion models to reconstruct high-resolution images with high semantic fidelity from fMRI signals. It explains how these models can generate diverse high-resolution images with high semantic fidelity of text-conditioning and high computational efficiency, and it provides biological interpretations of each component of the LDM. It further explains how the text-to-image conversion process implemented by an LDM incorporates the semantic information expressed by the conditional text, while at the same time maintaining the appearance of the original image.</p>
	
		<h2>Page 3</h2>
		<p>This page discusses how neuroscientists use encoding models to understand deep-learning models from a biological perspective. It explains how activation patterns observed within early and late layers of a CNN correspond to the neural activity patterns measured from early and late layers of visual cortex, suggesting a hierarchical correspondence between latent representations of a CNN and those present in the brain. It also explains how this approach has been applied primarily to vision science, but has recently been extended to other sensory modalities and higher functions. The methods used include the Natural Scenes Dataset (NSD) and a Latent Diffusion Model (LDM). The LDM consists of an image encoder, an image decoder, and a text encoder (CLIP). Decoding analysis is used to decode latent representations of the presented image and associated text from fMRI signals within early and higher visual cortices, respectively. Encoding analysis is used to predict fMRI signals from different components of the LDM, including latent vectors, denoising processes, conditioning operations, and U-net components.</p>
	
		<h2>Page 4</h2>
		<p>This study used latent diffusion models (LDMs) to reconstruct images from fMRI signals in three simple steps. First, a latent representation of the presented image was predicted from fMRI signals within early visual cortex. This was then processed by a decoder of an autoencoder to produce a coarse decoded image, and then resized it to 512x512. Second, the coarse image was processed by an encoder of an autoencoder, and then added noise through the diffusion process. Third, a latent representation of texts was decoded from fMRI signals within higher (ventral) visual cortex. The noise-added latent representations of the coarse image and decoded text were used as input to a denoising U-Net to produce a generated latent representation, which was then used as input to the decoding module of the autoencoder to produce a final reconstructed image. The accuracy of image reconstruction was evaluated objectively (perceptual similarity metrics) and subjectively (human raters).</p>
	
		<h2>Page 5</h2>
		<p>This page describes an experiment in which whole-brain voxel-wise encoding models were constructed to interpret the internal operations of latent-dirichlet models (LDMs). The models were built for four settings: linear models to predict voxel activity from the three latent representations of the LDM independently, incorporating z and c into a single model, examining how zc changes through the denoising process, and extracting features from different layers of U-Net. The results showed that images reconstructed using zc could generate high-resolution images with high semantic fidelity. Further, the reconstruction quality was stable and accurate across subjects. The evaluation was done using Pearson's correlation coefficients between predicted and measured fMRI signals, and the statistical threshold was set at P< 0.05.</p>
	
		<h2>Page 6</h2>
		<p>This page summarizes the results of a study that compared the accuracy of three different latent representations (z, c, and zc) of the Low-dimensional Model (LDM) across four subjects. The objective evaluation showed that images reconstructed using zc generally had higher accuracy values than those reconstructed using only z or c. The subjective evaluation showed that accuracy values of images obtained from c were higher than those obtained from z, while zc resulted in the highest accuracy compared with the other two methods. The Encoding Model showed that z produced high prediction performance in the posterior part of visual cortex, namely early visual cortex, and c produced the highest prediction performance in higher visual cortex. zc carried a representation that was very similar to z, showing high prediction performance for early visual cortex.</p>
	
		<h2>Page 7</h2>
		<p>This page discusses the results of an analysis of a voxel-wise encoding model applied to test images in a single subject. It found that when a small amount of noise was added, the original image predicted voxel activity better than the noise-added image across cortex. However, when the level of noise was increased, the noise-added image predicted voxel activity within higher visual cortex better than the original image, indicating that the semantic content of the image was gradually emphasized. An additional analysis was conducted to compare the unique variance explained by the two models. Finally, the noise-added latent representation was studied over the iterative denoising process. The results showed that during the early stages of the denoising process, the original image signals dominated prediction of fMRI signals, while during the middle step the noise-added image predicted activity within higher visual cortex much better than the original image. The copyright holder for this preprint is the author/funder, who has granted bioRxiv a license to display the preprint in perpetuity.</p>
	
		<h2>Page 8</h2>
		<p>This paper presents a novel visual reconstruction method using Latent Diffusion Models (LDMs). The method reconstructs high-resolution images with high semantic fidelity from human brain activity. It does not require training or fine-tuning of complex deep-learning models, only linear mappings from fMRI to latent representations within LDMs. Through encoding models, the authors provide a quantitative interpretation for the internal components of the LDM, demonstrating the emergence of semantic content, layer-wise characterization of U-Net, and a quantitative interpretation of image-to-image transformations with different noise levels.</p>
	
		<h2>Page 9</h2>
		<p>This page discusses research conducted by JSPS KAKENHI (19H05725), MEXT/JSPS KAKENHI JP18H05522, JSTCREST JPMJCR18A5 and ERATO JPMJER1801. It examines how cognitive neuroscience and artificial intelligence can be bridged using massive 7T fMRI datasets, self-supervision in natural-image reconstruction from fMRI, the contributions of functional and deep neural network features to representational similarity of scenes in human brain and behavior, the generic decoding of seen and imagined objects using hierarchical visual features, the neural representation of visually evoked emotion, denoising diffusion probabilistic models, reconstructing perceptive images from brain activity by shape-semantic GAN, diffusion-driven test-time adaptation, self-supervised natural image reconstruction and large-scale semantic classification from brain activity, shared computational principles for language processing in humans and deep language models, the distinct contributions of functional and deep neural network features to representational similarity of scenes in human brain and behavior, deep neural networks reveal a gradient in the complexity of neural representations across the ventral stream, decoding the semantic content of natural movies from human brain activity, JPEG artifact correction using denoising diffusion restoration models, identifying natural images from human brain activity, a task-optimized neural network replicates human auditory behavior, predicts brain responses and reveals a cortical processing hierarchy, distinct dimensions of emotion in the human brain and their representation on the cortical surface, generic decoding of seen and imagined objects using hierarchical visual features, neural decoding of visual imagery during sleep, back to the source: diffusion-driven test-time adaptation, cascaded tuning to amplitude modulation for natural sound recognition, feature-space selection with banded ridge regression, brain2pix: fully convolutional naturalistic video reconstruction from brain activity, and mind reader: reconstructing complex images from brain activities.</p>
	
		<h2>Page 10</h2>
		<p>This page presents research on human brain activity using a combination of multiscale local image decoders. It includes 27-52 references to papers discussing reconstructing natural scenes from fMRI patterns, quantitative models of diverse cognitive functions, voxel-wise encoding models, Bayesian reconstruction of natural images, decoding naturalistic experiences from brain activity, high-resolution image synthesis, image-to-image diffusion models, photorealistic text-to-image diffusion models, image super-resolution, unpaired image translation, predictive processing, generative adversarial networks for reconstructing natural images from brain activity, deep image reconstruction from brain activity, generative modeling by estimating gradients of the data distribution, deep unsupervised learning, end-to-end deep image reconstruction from human brain activity, and rethinking the inception architecture for computer vision. The copyright holder for this preprint is the author/funder who has granted bioRxiv a license to display the preprint in perpetuity.</p>
	
		<h2>Page 11</h2>
		<p>This page provides information regarding three papers on deep learning in relation to neural computation and dynamic natural vision. The papers are written by Pascal Vincent, Haiguang Wen et al., and Daniel LK Yamins et al. respectively. They focus on score matching and denoising autoencoders, neural encoding and decoding with deep learning, and performance-optimized hierarchical models predicting neural responses in higher visual cortex. This page is licensed under a CC-BY 4.0 International license and the copyright holder is the author/funder who has granted bioRxiv a license to display the preprint in perpetuity.</p>
	
</body>
</html>