<!DOCTYPE html>
<html>
<head>
	<title>Summaries of the doc</title>
    <style>
        .center {
            text-align: center;
        }
    </style>
</head>
<body>
	<h1 class="center">High-Resolution Image Reconstruction with Latent Diffusion Models from Human Brain Activity</h1>
	
		<h2>Page 1</h2>
		<p>This paper presents a new method for reconstructing high-resolution images from human brain activity obtained via functional magnetic resonance imaging (fMRI). The proposed method is based on a latent diffusion model (LDM) termed Stable Diffusion which reduces the computational cost of diffusion models while preserving their high generative performance. The authors also provide a quantitative interpretation of different LDM components from a neuroscientific perspective and show that the proposed method can reconstruct high-resolution images with high fidelity.</p>
	
		<h2>Page 2</h2>
		<p>This paper attempts to reconstruct visual images from fMRI signals using an LDM named Stable Diffusion. This architecture is trained on a large dataset and carries high text-to-image generative performance. It is shown that the framework can reconstruct high-resolution images with high semantic fidelity without any training or fine-tuning of complex deep-learning models. The paper also provides biological interpretations of each component of the LDM, including forward/reverse diffusion processes, U-Net, and latent representations with different noise levels.</p>
	
		<h2>Page 3</h2>
		<p>This page discusses the use of encoding models to understand deep learning models from a biological perspective. Neuroscientists have employed encoding models to build a predictive model of brain activity from features extracted from different components of the deep learning models. This approach has been applied primarily to vision science, but has recently been extended to other sensory modalities and higher functions. The methods outlined involve using the Natural Scenes Dataset (NSD) which provides data acquired from a 7-Tesla fMRI scanner over 30-40 sessions during which each subject viewed three repetitions of 10,000 images. A Latent Diffusion Model (LDM) is used to analyze data for four of the eight subjects who completed all imaging sessions. This model includes an image encoder, an image decoder, and a text encoder which are used to decode latent representations of the presented image and associated text from fMRI signals within early and higher visual cortices. Encoding models are then built to predict fMRI signals from different components of the LDM.</p>
	
		<h2>Page 4</h2>
		<p>This study describes a method of reconstructing images from fMRI signals using a latent diffusion model (LDM). The method consists of three steps: (i) predicting a latent representation of the presented image from fMRI signals within early visual cortex; (ii) processing the latent representation through an autoencoder to produce a coarse decoded image; and (iii) decoding latent text representations from fMRI signals within higher (ventral) visual cortex and using the noise-added latent representations of the coarse image and decoded text to generate a final reconstructed image. The accuracy of the image reconstruction was evaluated both objectively (using perceptual similarity metrics) and subjectively (using human raters). As control analyses, images were also generated using only the latent representation of the original image or the latent representation of the text.</p>
	
		<h2>Page 5</h2>
		<p>This page describes a study which examined the internal operations of Latent Dirichlet Allocation (LDM) models by mapping them to brain activity. Four settings were tested: linear models to predict voxel activity from three latent representations of the LDM independently (z, c, and zc); a single model incorporating z and c with varying levels of noise added to z; extracting zc from the early, middle, and late steps of the denoising process; and extracting features from different layers of U-Net. Model weights were estimated from training data using L2-regularized linear regression, and subsequently applied to test data. Results were evaluated using Pearsonâ€™s correlation coefficients between predicted and measured fMRI signals, and statistical significance was determined by comparing to the null distribution of correlations between two independent Gaussian random vectors. Results showed that images reconstructed using zc could generate high-resolution images with high semantic fidelity.</p>
	
		<h2>Page 6</h2>
		<p>This page summarizes a study that compared the accuracy of images reconstructed using different methods (PSM, Human, CLIP, and CNN). These methods were evaluated using objective and subjective criteria. Results showed that images reconstructed using zcare generally associated with higher accuracy values than images reconstructed using only zorc. When only zwas used, accuracy values were particularly high for PSMs derived from early layers of CLIP and CNN. On the other hand, when only cwas used, accuracy values were higher for PSMs derived from late layers. In the subjective evaluation, accuracy values of images obtained from care higher than those obtained from z, while zcresulted in the highest accuracy compared with the other two methods. The study also compared the prediction performance of three types of latent representations associated with the LDM (z, c, and zc). Results showed that zproduced high prediction performance in early visual cortex, while cproduced the highest prediction performance in higher visual cortex. zccarried a representation that was very similar to z, showing high prediction performance for early visual cortex.</p>
	
		<h2>Page 7</h2>
		<p>This page presents the results of an analysis conducted to compare the unique variance explained by two models, z and zc, when applied to held-out test images in a single subject. The results showed that when a small amount of noise was added, z predicted voxel activity better than zc across the cortex. However, when the level of noise was increased, zc predicted voxel activity within higher visual cortex better than z, indicating that the semantic content of the image was gradually emphasized. Furthermore, the analysis showed that during the early stages of the denoising process, z signals dominated prediction of fMRI signals, while during the middle step of the denoising process, zc predicted activity within higher visual cortex much better than z, indicating that the bulk of the semantic content emerges at this stage.</p>
	
		<h2>Page 8</h2>
		<p>This study proposes a novel visual reconstruction method using latent diffusion models (LDMs) to reconstruct high-resolution images with high semantic fidelity from human brain activity. Results suggest that during the early phase of the denoising process, the bottleneck layer of U-Net produces the highest prediction performance across cortex. As denoising progresses, a functional dissociation among U-Net layers emerges within visual cortex, with the first layer tending to represent fine-scale details in early visual areas, and the bottleneck layer corresponding to higher-order information in more ventral, semantic areas. This study provides a quantitative interpretation of the internal components of the LDM and is the first to provide a quantitative interpretation from a biological perspective.</p>
	
		<h2>Page 9</h2>
		<p>This page summarizes research supported by MEXT/JSPS KAKENHI JP18H05522, JSTCREST JPMJCR18A5, and ERATO JPMJER1801. It discusses various studies that explore the relationship between cognitive neuroscience and artificial intelligence, natural image reconstruction from fMRI, the neural representation of visually evoked emotion, deep neural networks, diffusion models, and more. It also discusses various methods used to study these topics, such as self-supervised natural image reconstruction, shape-semantic GANs, denoising diffusion probabilistic models, and more.</p>
	
		<h2>Page 10</h2>
		<p>This page discusses various studies on reconstructing natural images from human brain activity using a combination of multiscale local image decoders. It describes different methods such as Bayesian reconstruction, deep learning, generative adversarial networks, unsupervised learning, deep image reconstruction, score-based generative modeling, and inception architecture for computer vision. It also discusses their applications in language understanding, naturalistic experiences, cognitive functions, state, trait, and pathological anxiety, and non-invasive brain recordings. The page is copyright protected and is available under CC-BY 4.0 International license.</p>
	
		<h2>Page 11</h2>
		<p>This page discusses three papers related to deep learning and its applications in neural encoding and decoding. The papers discuss score matching and denoising autoencoders (paper 53), neural encoding and decoding with deep learning for dynamic natural vision (paper 54), and performance-optimized hierarchical models predicting neural responses in higher visual cortex (paper 55). The page is licensed under a CC-BY 4.0 International license and was posted December 1, 2022.</p>
	
</body>
</html>